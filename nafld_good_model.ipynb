{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b848806",
   "metadata": {},
   "source": [
    "# Model - 1 - CNN Model (Best Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da1943c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score,accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# Preprocess the data (e.g., handle missing values, normalize/scale features)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "df = pd.read_csv('train.csv')\n",
    "train_data1 = df.iloc[:, [7, 8, 21, 22, 24, 25, 27, 29]]\n",
    "train_labels = df.iloc[:, [0]]\n",
    "dftest = pd.read_csv('test.csv')\n",
    "val_data1 = dftest.iloc[:, [7, 8, 21, 22, 24, 25, 27, 29]]\n",
    "val_labels = dftest.iloc[:, [0]]\n",
    "\n",
    "# Create an instance of StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data\n",
    "scaler.fit(train_data1)\n",
    "\n",
    "# Scale the training data\n",
    "train_data = scaler.transform(train_data1)\n",
    "train_l = train_labels.to_numpy()\n",
    "# Scale the validation data\n",
    "val_data = scaler.transform(val_data1)\n",
    "val_l = val_labels.to_numpy()\n",
    "# Reshape the data for CNN input\n",
    "train_data = train_data.reshape(train_data.shape[0], train_data.shape[1], 1)\n",
    "val_data = val_data.reshape(val_data.shape[0], val_data.shape[1], 1)\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(train_data.shape[1], 1)))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 7\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "kf = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "train_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "auc_roc_scores = []\n",
    "val_scores = []\n",
    "best_model = None\n",
    "best_auc_roc = 0.0\n",
    "for train_index, val_index in kf.split(train_data):\n",
    "    # Split the data into training and validation sets for the current fold\n",
    "    train_fold_data, val_fold_data = train_data[train_index], train_data[val_index]\n",
    "    train_fold_labels, val_fold_labels = train_l[train_index], train_l[val_index]\n",
    "\n",
    "    # Train the model on the current fold\n",
    "    history = model.fit(train_fold_data, train_fold_labels, epochs=50, batch_size=32, validation_data=(val_fold_data, val_fold_labels))\n",
    "\n",
    "    # Evaluate the model on the training and validation sets of the current fold\n",
    "    train_predictions = model.predict(train_fold_data)\n",
    "    val_predictions = model.predict(val_fold_data)\n",
    "    val_predictions = np.round(val_predictions)\n",
    "\n",
    "    # Calculate accuracy scores for training and validation sets\n",
    "    train_acc = model.evaluate(train_fold_data, train_fold_labels, verbose=0)[1]\n",
    "    val_acc = model.evaluate(val_fold_data, val_fold_labels, verbose=0)[1]\n",
    "\n",
    "    train_scores.append(train_acc)\n",
    "    val_scores.append(val_acc)\n",
    "    \n",
    "    auc_roc = roc_auc_score(val_fold_labels, val_predictions)\n",
    "    \n",
    "    precision = precision_score(val_fold_labels, val_predictions)\n",
    "    recall = recall_score(val_fold_labels, val_predictions)\n",
    "    f1 = f1_score(val_fold_labels, val_predictions)\n",
    "    auc_roc = roc_auc_score(val_fold_labels, val_predictions)\n",
    "\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    auc_roc_scores.append(auc_roc)\n",
    "\n",
    "\n",
    "# Compute the average scores across all folds\n",
    "avg_precision = np.mean(precision_scores)\n",
    "avg_recall = np.mean(recall_scores)\n",
    "avg_f1 = np.mean(f1_scores)\n",
    "avg_auc_roc = np.mean(auc_roc_scores)\n",
    "avg_val_acc=np.mean(val_scores)\n",
    "avg_train_acc=np.mean(train_scores)\n",
    "print('Average Precision:', avg_precision)\n",
    "print('Average Recall:', avg_recall)\n",
    "print('Average F1-score:', avg_f1)\n",
    "print('Average AUC-ROC:', avg_auc_roc)\n",
    "print('average val accuracy',avg_val_acc)\n",
    "print('average train accuracy',avg_train_acc)\n",
    "# Calculate bias and variance\n",
    "\n",
    "# Plot bias and variance\n",
    "# plt.bar(['Bias', 'Variance'], [bias, variance])\n",
    "# plt.xlabel('Error Type')\n",
    "# plt.ylabel('Error Value')\n",
    "# plt.title('Bias-Variance Tradeoff')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136b89cc",
   "metadata": {},
   "source": [
    "# Model - 2 - ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f064b2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score,accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# Preprocess the data (e.g., handle missing values, normalize/scale features)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "df = pd.read_csv('train.csv')\n",
    "train_data1 = df.iloc[:, [7, 8, 21, 22, 24, 25, 27, 29]]\n",
    "train_labels = df.iloc[:, [0]]\n",
    "dftest = pd.read_csv('test.csv')\n",
    "val_data1 = dftest.iloc[:, [7, 8, 21, 22, 24, 25, 27, 29]]\n",
    "val_labels = dftest.iloc[:, [0]]\n",
    "\n",
    "# Create an instance of StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data\n",
    "scaler.fit(train_data1)\n",
    "\n",
    "# Scale the training data\n",
    "train_data = scaler.transform(train_data1)\n",
    "train_l = train_labels.to_numpy()\n",
    "# Scale the validation data\n",
    "val_data = scaler.transform(val_data1)\n",
    "val_l = val_labels.to_numpy()\n",
    "# Reshape the data for CNN input\n",
    "train_data = train_data.reshape(train_data.shape[0], train_data.shape[1], 1)\n",
    "val_data = val_data.reshape(val_data.shape[0], val_data.shape[1], 1)\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "model.add(Dense(32,activation='relu',input_shape=(8,)))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16,activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 7\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "kf = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "train_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "auc_roc_scores = []\n",
    "val_scores = []\n",
    "best_model = None\n",
    "best_auc_roc = 0.0\n",
    "for train_index, val_index in kf.split(train_data):\n",
    "    # Split the data into training and validation sets for the current fold\n",
    "    train_fold_data, val_fold_data = train_data[train_index], train_data[val_index]\n",
    "    train_fold_labels, val_fold_labels = train_l[train_index], train_l[val_index]\n",
    "\n",
    "    # Train the model on the current fold\n",
    "    history = model.fit(train_fold_data, train_fold_labels, epochs=50, batch_size=32, validation_data=(val_fold_data, val_fold_labels))\n",
    "\n",
    "    # Evaluate the model on the training and validation sets of the current fold\n",
    "    train_predictions = model.predict(train_fold_data)\n",
    "    val_predictions = model.predict(val_fold_data)\n",
    "    val_predictions = np.round(val_predictions)\n",
    "\n",
    "    # Calculate accuracy scores for training and validation sets\n",
    "    train_acc = model.evaluate(train_fold_data, train_fold_labels, verbose=0)[1]\n",
    "    val_acc = model.evaluate(val_fold_data, val_fold_labels, verbose=0)[1]\n",
    "\n",
    "    train_scores.append(train_acc)\n",
    "    val_scores.append(val_acc)\n",
    "    \n",
    "    auc_roc = roc_auc_score(val_fold_labels, val_predictions)\n",
    "    \n",
    "    precision = precision_score(val_fold_labels, val_predictions)\n",
    "    recall = recall_score(val_fold_labels, val_predictions)\n",
    "    f1 = f1_score(val_fold_labels, val_predictions)\n",
    "    auc_roc = roc_auc_score(val_fold_labels, val_predictions)\n",
    "\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    auc_roc_scores.append(auc_roc)\n",
    "\n",
    "\n",
    "# Compute the average scores across all folds\n",
    "avg_precision = np.mean(precision_scores)\n",
    "avg_recall = np.mean(recall_scores)\n",
    "avg_f1 = np.mean(f1_scores)\n",
    "avg_auc_roc = np.mean(auc_roc_scores)\n",
    "avg_val_acc=np.mean(val_scores)\n",
    "avg_train_acc=np.mean(train_scores)\n",
    "print('Average Precision:', avg_precision)\n",
    "print('Average Recall:', avg_recall)\n",
    "print('Average F1-score:', avg_f1)\n",
    "print('Average AUC-ROC:', avg_auc_roc)\n",
    "print('average val accuracy',avg_val_acc)\n",
    "print('average train accuracy',avg_train_acc)\n",
    "# Calculate bias and variance\n",
    "\n",
    "# Plot bias and variance\n",
    "# plt.bar(['Bias', 'Variance'], [bias, variance])\n",
    "# plt.xlabel('Error Type')\n",
    "# plt.ylabel('Error Value')\n",
    "# plt.title('Bias-Variance Tradeoff')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d285153",
   "metadata": {},
   "source": [
    "# Model - 3 ANN Model (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4b5e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score\n",
    "\n",
    "# Load and preprocess your clinical data\n",
    "df = pd.read_csv('train.csv')\n",
    "train_data = df.iloc[:, [7, 8, 21, 22, 24, 25, 27, 29]].values\n",
    "train_labels = df.iloc[:, [0]].values\n",
    "\n",
    "dftest = pd.read_csv('test.csv')\n",
    "val_data = dftest.iloc[:, [7, 8, 21, 22, 24, 25, 27, 29]].values\n",
    "val_labels = dftest.iloc[:, [0]].values\n",
    "\n",
    "# Create an instance of StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data\n",
    "scaler.fit(train_data)\n",
    "\n",
    "# Scale the training and validation data\n",
    "train_data = scaler.transform(train_data)\n",
    "val_data = scaler.transform(val_data)\n",
    "\n",
    "# Build a simple neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(8,)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 7\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "kf = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "train_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "auc_roc_scores = []\n",
    "val_scores = []\n",
    "\n",
    "for train_index, val_index in kf.split(train_data):\n",
    "    train_fold_data, val_fold_data = train_data[train_index], train_data[val_index]\n",
    "    train_fold_labels, val_fold_labels = train_labels[train_index], train_labels[val_index]\n",
    "\n",
    "    history = model.fit(train_fold_data, train_fold_labels, epochs=50, batch_size=32, validation_data=(val_fold_data, val_fold_labels))\n",
    "\n",
    "    val_predictions = model.predict(val_fold_data)\n",
    "    val_predictions = np.round(val_predictions)\n",
    "\n",
    "    precision = precision_score(val_fold_labels, val_predictions)\n",
    "    recall = recall_score(val_fold_labels, val_predictions)\n",
    "    f1 = f1_score(val_fold_labels, val_predictions)\n",
    "    auc_roc = roc_auc_score(val_fold_labels, val_predictions)\n",
    "    accuracy = accuracy_score(val_fold_labels, val_predictions)\n",
    "\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    auc_roc_scores.append(auc_roc)\n",
    "    val_scores.append(accuracy)\n",
    "\n",
    "avg_precision = np.mean(precision_scores)\n",
    "avg_recall = np.mean(recall_scores)\n",
    "avg_f1 = np.mean(f1_scores)\n",
    "avg_auc_roc = np.mean(auc_roc_scores)\n",
    "avg_val_acc = np.mean(val_scores)\n",
    "print('Average Precision:', avg_precision)\n",
    "print('Average Recall:', avg_recall)\n",
    "print('Average F1-score:', avg_f1)\n",
    "print('Average AUC-ROC:', avg_auc_roc)\n",
    "print('Average Validation Accuracy:', avg_val_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d6cca3",
   "metadata": {},
   "source": [
    "# Model - 4 - CNN Model (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b1c645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# Preprocess the data (e.g., handle missing values, normalize/scale features)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "df = pd.read_csv('train.csv')\n",
    "train_data1 = df.iloc[:, [7, 8, 21, 22, 24, 25, 27, 29]]\n",
    "train_labels = df.iloc[:, [0]]\n",
    "dftest = pd.read_csv('test.csv')\n",
    "val_data1 = dftest.iloc[:, [7, 8, 21, 22, 24, 25, 27, 29]]\n",
    "val_labels = dftest.iloc[:, [0]]\n",
    "\n",
    "# Create an instance of StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data\n",
    "scaler.fit(train_data1)\n",
    "\n",
    "# Scale the training data\n",
    "train_data = scaler.transform(train_data1)\n",
    "train_l = train_labels.to_numpy()\n",
    "# Scale the validation data\n",
    "val_data = scaler.transform(val_data1)\n",
    "val_l = val_labels.to_numpy()\n",
    "# Reshape the data for CNN input\n",
    "train_data = train_data.reshape(train_data.shape[0], train_data.shape[1], 1)\n",
    "val_data = val_data.reshape(val_data.shape[0], val_data.shape[1], 1)\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(train_data.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 5\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "kf = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "auc_roc_scores = []\n",
    "\n",
    "for train_index, val_index in kf.split(train_data):\n",
    "    # Split the data into training and validation sets for the current fold\n",
    "    train_fold_data, val_fold_data = train_data[train_index], train_data[val_index]\n",
    "    train_fold_labels, val_fold_labels = train_l[train_index], train_l[val_index]\n",
    "\n",
    "    # Train the model on the current fold\n",
    "    model.fit(train_fold_data, train_fold_labels, epochs=50, batch_size=32, validation_data=(val_fold_data, val_fold_labels))\n",
    "\n",
    "    # Evaluate the model on the validation set of the current fold\n",
    "    val_predictions = model.predict(val_fold_data)\n",
    "    val_predictions = np.round(val_predictions)  # Convert probabilities to binary predictions\n",
    "\n",
    "    precision = precision_score(val_fold_labels, val_predictions)\n",
    "    recall = recall_score(val_fold_labels, val_predictions)\n",
    "    f1 = f1_score(val_fold_labels, val_predictions)\n",
    "    auc_roc = roc_auc_score(val_fold_labels, val_predictions)\n",
    "\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    auc_roc_scores.append(auc_roc)\n",
    "\n",
    "# Compute the average scores across all folds\n",
    "avg_precision = np.mean(precision_scores)\n",
    "avg_recall = np.mean(recall_scores)\n",
    "avg_f1 = np.mean(f1_scores)\n",
    "avg_auc_roc = np.mean(auc_roc_scores)\n",
    "\n",
    "print('Average Precision:', avg_precision)\n",
    "print('Average Recall:', avg_recall)\n",
    "print('Average F1-score:', avg_f1)\n",
    "print('Average AUC-ROC:', avg_auc_roc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda7ef6e",
   "metadata": {},
   "source": [
    "# Model - 5 CNN Model (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a204223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "57/57 [==============================] - 2s 8ms/step - loss: 0.5591 - accuracy: 0.7528 - val_loss: 0.5457 - val_accuracy: 0.7285\n",
      "Epoch 2/50\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.5043 - accuracy: 0.7765 - val_loss: 0.5398 - val_accuracy: 0.7196\n",
      "Epoch 3/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.4972 - accuracy: 0.7815 - val_loss: 0.5342 - val_accuracy: 0.7285\n",
      "Epoch 4/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.4944 - accuracy: 0.7815 - val_loss: 0.5345 - val_accuracy: 0.7241\n",
      "Epoch 5/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.4865 - accuracy: 0.7809 - val_loss: 0.5363 - val_accuracy: 0.7219\n",
      "Epoch 6/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.4826 - accuracy: 0.7859 - val_loss: 0.5472 - val_accuracy: 0.7285\n",
      "Epoch 7/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.4816 - accuracy: 0.7870 - val_loss: 0.5430 - val_accuracy: 0.7329\n",
      "Epoch 8/50\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4816 - accuracy: 0.7859 - val_loss: 0.5337 - val_accuracy: 0.7351\n",
      "Epoch 9/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.4708 - accuracy: 0.7870 - val_loss: 0.5362 - val_accuracy: 0.7351\n",
      "Epoch 10/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7842 - val_loss: 0.5497 - val_accuracy: 0.7461\n",
      "Epoch 11/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.4642 - accuracy: 0.7947 - val_loss: 0.5380 - val_accuracy: 0.7417\n",
      "Epoch 12/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.4579 - accuracy: 0.7991 - val_loss: 0.5504 - val_accuracy: 0.7196\n",
      "Epoch 13/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.4600 - accuracy: 0.7980 - val_loss: 0.5487 - val_accuracy: 0.7351\n",
      "Epoch 14/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.4490 - accuracy: 0.7980 - val_loss: 0.5719 - val_accuracy: 0.7285\n",
      "Epoch 15/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4495 - accuracy: 0.8030 - val_loss: 0.5437 - val_accuracy: 0.7263\n",
      "Epoch 16/50\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.8063 - val_loss: 0.5956 - val_accuracy: 0.7351\n",
      "Epoch 17/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.4388 - accuracy: 0.8030 - val_loss: 0.5750 - val_accuracy: 0.7461\n",
      "Epoch 18/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.4332 - accuracy: 0.8113 - val_loss: 0.5928 - val_accuracy: 0.7219\n",
      "Epoch 19/50\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.8008 - val_loss: 0.5697 - val_accuracy: 0.7329\n",
      "Epoch 20/50\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.8151 - val_loss: 0.5872 - val_accuracy: 0.7263\n",
      "Epoch 21/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4255 - accuracy: 0.8146 - val_loss: 0.5782 - val_accuracy: 0.7196\n",
      "Epoch 22/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.8162 - val_loss: 0.5895 - val_accuracy: 0.7174\n",
      "Epoch 23/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4121 - accuracy: 0.8184 - val_loss: 0.6379 - val_accuracy: 0.7130\n",
      "Epoch 24/50\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.4147 - accuracy: 0.8201 - val_loss: 0.6043 - val_accuracy: 0.7307\n",
      "Epoch 25/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3981 - accuracy: 0.8267 - val_loss: 0.6310 - val_accuracy: 0.7373\n",
      "Epoch 26/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4016 - accuracy: 0.8295 - val_loss: 0.6152 - val_accuracy: 0.7174\n",
      "Epoch 27/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3902 - accuracy: 0.8328 - val_loss: 0.6656 - val_accuracy: 0.7263\n",
      "Epoch 28/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3852 - accuracy: 0.8350 - val_loss: 0.6602 - val_accuracy: 0.7196\n",
      "Epoch 29/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4045 - accuracy: 0.8212 - val_loss: 0.6322 - val_accuracy: 0.7263\n",
      "Epoch 30/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3924 - accuracy: 0.8328 - val_loss: 0.6575 - val_accuracy: 0.7086\n",
      "Epoch 31/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3791 - accuracy: 0.8361 - val_loss: 0.7120 - val_accuracy: 0.7086\n",
      "Epoch 32/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3656 - accuracy: 0.8466 - val_loss: 0.6699 - val_accuracy: 0.7351\n",
      "Epoch 33/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3587 - accuracy: 0.8521 - val_loss: 0.6860 - val_accuracy: 0.7241\n",
      "Epoch 34/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3529 - accuracy: 0.8598 - val_loss: 0.7512 - val_accuracy: 0.7219\n",
      "Epoch 35/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3513 - accuracy: 0.8582 - val_loss: 0.7259 - val_accuracy: 0.7285\n",
      "Epoch 36/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3528 - accuracy: 0.8493 - val_loss: 0.7334 - val_accuracy: 0.7329\n",
      "Epoch 37/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3370 - accuracy: 0.8515 - val_loss: 0.7431 - val_accuracy: 0.7130\n",
      "Epoch 38/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3450 - accuracy: 0.8549 - val_loss: 0.7383 - val_accuracy: 0.6887\n",
      "Epoch 39/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3228 - accuracy: 0.8675 - val_loss: 0.7827 - val_accuracy: 0.7174\n",
      "Epoch 40/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3177 - accuracy: 0.8720 - val_loss: 0.7835 - val_accuracy: 0.7329\n",
      "Epoch 41/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3024 - accuracy: 0.8786 - val_loss: 0.8189 - val_accuracy: 0.7241\n",
      "Epoch 42/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2989 - accuracy: 0.8786 - val_loss: 0.8329 - val_accuracy: 0.6976\n",
      "Epoch 43/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3021 - accuracy: 0.8764 - val_loss: 0.8307 - val_accuracy: 0.7064\n",
      "Epoch 44/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3117 - accuracy: 0.8742 - val_loss: 0.8596 - val_accuracy: 0.7241\n",
      "Epoch 45/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2741 - accuracy: 0.8891 - val_loss: 0.9074 - val_accuracy: 0.6777\n",
      "Epoch 46/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2691 - accuracy: 0.8968 - val_loss: 0.9409 - val_accuracy: 0.7130\n",
      "Epoch 47/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2716 - accuracy: 0.8962 - val_loss: 0.9820 - val_accuracy: 0.7152\n",
      "Epoch 48/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2815 - accuracy: 0.8852 - val_loss: 0.9396 - val_accuracy: 0.6843\n",
      "Epoch 49/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2739 - accuracy: 0.8758 - val_loss: 0.9858 - val_accuracy: 0.7108\n",
      "Epoch 50/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2500 - accuracy: 0.9023 - val_loss: 1.0576 - val_accuracy: 0.7130\n",
      "57/57 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.8361 - val_loss: 0.3257 - val_accuracy: 0.8565\n",
      "Epoch 2/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3579 - accuracy: 0.8609 - val_loss: 0.3150 - val_accuracy: 0.8565\n",
      "Epoch 3/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3411 - accuracy: 0.8598 - val_loss: 0.3355 - val_accuracy: 0.8543\n",
      "Epoch 4/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3264 - accuracy: 0.8742 - val_loss: 0.3333 - val_accuracy: 0.8587\n",
      "Epoch 5/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3183 - accuracy: 0.8720 - val_loss: 0.3691 - val_accuracy: 0.8609\n",
      "Epoch 6/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3071 - accuracy: 0.8802 - val_loss: 0.3540 - val_accuracy: 0.8411\n",
      "Epoch 7/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2964 - accuracy: 0.8863 - val_loss: 0.3558 - val_accuracy: 0.8389\n",
      "Epoch 8/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2906 - accuracy: 0.8863 - val_loss: 0.3654 - val_accuracy: 0.8455\n",
      "Epoch 9/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2747 - accuracy: 0.8957 - val_loss: 0.3903 - val_accuracy: 0.8234\n",
      "Epoch 10/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2670 - accuracy: 0.8985 - val_loss: 0.4018 - val_accuracy: 0.8190\n",
      "Epoch 11/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2583 - accuracy: 0.8929 - val_loss: 0.4156 - val_accuracy: 0.8366\n",
      "Epoch 12/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2459 - accuracy: 0.9062 - val_loss: 0.5110 - val_accuracy: 0.8146\n",
      "Epoch 13/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2762 - accuracy: 0.8847 - val_loss: 0.4237 - val_accuracy: 0.8057\n",
      "Epoch 14/50\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2529 - accuracy: 0.8962 - val_loss: 0.5008 - val_accuracy: 0.7792\n",
      "Epoch 15/50\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.2407 - accuracy: 0.9034 - val_loss: 0.5107 - val_accuracy: 0.8212\n",
      "Epoch 16/50\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.2172 - accuracy: 0.9227 - val_loss: 0.4735 - val_accuracy: 0.8035\n",
      "Epoch 17/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2174 - accuracy: 0.9172 - val_loss: 0.4992 - val_accuracy: 0.8300\n",
      "Epoch 18/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2092 - accuracy: 0.9167 - val_loss: 0.5199 - val_accuracy: 0.7925\n",
      "Epoch 19/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2124 - accuracy: 0.9111 - val_loss: 0.4842 - val_accuracy: 0.8079\n",
      "Epoch 20/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1943 - accuracy: 0.9260 - val_loss: 0.5537 - val_accuracy: 0.7682\n",
      "Epoch 21/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1943 - accuracy: 0.9216 - val_loss: 0.5476 - val_accuracy: 0.7903\n",
      "Epoch 22/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1866 - accuracy: 0.9294 - val_loss: 0.6260 - val_accuracy: 0.8035\n",
      "Epoch 23/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1852 - accuracy: 0.9321 - val_loss: 0.5969 - val_accuracy: 0.7859\n",
      "Epoch 24/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1620 - accuracy: 0.9365 - val_loss: 0.6511 - val_accuracy: 0.7660\n",
      "Epoch 25/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1595 - accuracy: 0.9387 - val_loss: 0.6861 - val_accuracy: 0.7881\n",
      "Epoch 26/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1431 - accuracy: 0.9448 - val_loss: 0.7915 - val_accuracy: 0.7881\n",
      "Epoch 27/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1552 - accuracy: 0.9459 - val_loss: 0.7515 - val_accuracy: 0.7770\n",
      "Epoch 28/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1305 - accuracy: 0.9487 - val_loss: 0.8235 - val_accuracy: 0.7881\n",
      "Epoch 29/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1390 - accuracy: 0.9503 - val_loss: 0.7403 - val_accuracy: 0.7815\n",
      "Epoch 30/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1825 - accuracy: 0.9260 - val_loss: 0.7795 - val_accuracy: 0.7903\n",
      "Epoch 31/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1819 - accuracy: 0.9266 - val_loss: 0.8695 - val_accuracy: 0.7726\n",
      "Epoch 32/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1348 - accuracy: 0.9514 - val_loss: 0.8222 - val_accuracy: 0.7815\n",
      "Epoch 33/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1182 - accuracy: 0.9536 - val_loss: 0.8789 - val_accuracy: 0.7682\n",
      "Epoch 34/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1177 - accuracy: 0.9514 - val_loss: 0.8239 - val_accuracy: 0.7616\n",
      "Epoch 35/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1225 - accuracy: 0.9564 - val_loss: 0.8613 - val_accuracy: 0.7726\n",
      "Epoch 36/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0862 - accuracy: 0.9685 - val_loss: 0.9321 - val_accuracy: 0.7815\n",
      "Epoch 37/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0815 - accuracy: 0.9730 - val_loss: 0.9574 - val_accuracy: 0.7660\n",
      "Epoch 38/50\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1207 - accuracy: 0.9525 - val_loss: 1.0794 - val_accuracy: 0.7285\n",
      "Epoch 39/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1041 - accuracy: 0.9597 - val_loss: 0.9844 - val_accuracy: 0.7572\n",
      "Epoch 40/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1136 - accuracy: 0.9586 - val_loss: 0.9137 - val_accuracy: 0.7594\n",
      "Epoch 41/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1121 - accuracy: 0.9625 - val_loss: 0.9673 - val_accuracy: 0.7792\n",
      "Epoch 42/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1086 - accuracy: 0.9630 - val_loss: 0.9290 - val_accuracy: 0.7550\n",
      "Epoch 43/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1141 - accuracy: 0.9636 - val_loss: 1.0174 - val_accuracy: 0.7550\n",
      "Epoch 44/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0894 - accuracy: 0.9663 - val_loss: 0.9974 - val_accuracy: 0.7483\n",
      "Epoch 45/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0842 - accuracy: 0.9719 - val_loss: 1.1300 - val_accuracy: 0.7792\n",
      "Epoch 46/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0811 - accuracy: 0.9746 - val_loss: 1.0458 - val_accuracy: 0.7638\n",
      "Epoch 47/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0593 - accuracy: 0.9774 - val_loss: 1.2093 - val_accuracy: 0.7439\n",
      "Epoch 48/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0700 - accuracy: 0.9746 - val_loss: 1.0666 - val_accuracy: 0.7748\n",
      "Epoch 49/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.9829 - val_loss: 1.1406 - val_accuracy: 0.7550\n",
      "Epoch 50/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9818 - val_loss: 1.1329 - val_accuracy: 0.7726\n",
      "57/57 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.8642 - val_loss: 0.4159 - val_accuracy: 0.8124\n",
      "Epoch 2/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3040 - accuracy: 0.8852 - val_loss: 0.2304 - val_accuracy: 0.9117\n",
      "Epoch 3/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2349 - accuracy: 0.9073 - val_loss: 0.1917 - val_accuracy: 0.9029\n",
      "Epoch 4/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2017 - accuracy: 0.9238 - val_loss: 0.2021 - val_accuracy: 0.9117\n",
      "Epoch 5/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1771 - accuracy: 0.9332 - val_loss: 0.2243 - val_accuracy: 0.9095\n",
      "Epoch 6/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1644 - accuracy: 0.9409 - val_loss: 0.2140 - val_accuracy: 0.9117\n",
      "Epoch 7/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9476 - val_loss: 0.2152 - val_accuracy: 0.9227\n",
      "Epoch 8/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1589 - accuracy: 0.9426 - val_loss: 0.3249 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1418 - accuracy: 0.9437 - val_loss: 0.2614 - val_accuracy: 0.9029\n",
      "Epoch 10/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1331 - accuracy: 0.9536 - val_loss: 0.3288 - val_accuracy: 0.8918\n",
      "Epoch 11/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1226 - accuracy: 0.9525 - val_loss: 0.3055 - val_accuracy: 0.8962\n",
      "Epoch 12/50\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1202 - accuracy: 0.9547 - val_loss: 0.2483 - val_accuracy: 0.8962\n",
      "Epoch 13/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1060 - accuracy: 0.9647 - val_loss: 0.2993 - val_accuracy: 0.8852\n",
      "Epoch 14/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1115 - accuracy: 0.9625 - val_loss: 0.2584 - val_accuracy: 0.9051\n",
      "Epoch 15/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0825 - accuracy: 0.9713 - val_loss: 0.3472 - val_accuracy: 0.8940\n",
      "Epoch 16/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0990 - accuracy: 0.9614 - val_loss: 0.3553 - val_accuracy: 0.8698\n",
      "Epoch 17/50\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.0853 - accuracy: 0.9708 - val_loss: 0.4167 - val_accuracy: 0.8830\n",
      "Epoch 18/50\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.0903 - accuracy: 0.9713 - val_loss: 0.3343 - val_accuracy: 0.8918\n",
      "Epoch 19/50\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.1240 - accuracy: 0.9509 - val_loss: 0.4975 - val_accuracy: 0.8720\n",
      "Epoch 20/50\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1710 - accuracy: 0.9321 - val_loss: 0.4481 - val_accuracy: 0.8587\n",
      "Epoch 21/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1269 - accuracy: 0.9525 - val_loss: 0.3251 - val_accuracy: 0.8808\n",
      "Epoch 22/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.1183 - accuracy: 0.9525 - val_loss: 0.4398 - val_accuracy: 0.8698\n",
      "Epoch 23/50\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0725 - accuracy: 0.9741 - val_loss: 0.3639 - val_accuracy: 0.8852\n",
      "Epoch 24/50\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0645 - accuracy: 0.9796 - val_loss: 0.4203 - val_accuracy: 0.8653\n",
      "Epoch 25/50\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.0513 - accuracy: 0.9851 - val_loss: 0.4474 - val_accuracy: 0.8675\n",
      "Epoch 26/50\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.0641 - accuracy: 0.9785 - val_loss: 0.6364 - val_accuracy: 0.8543\n",
      "Epoch 27/50\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.0629 - accuracy: 0.9779 - val_loss: 0.4778 - val_accuracy: 0.8609\n",
      "Epoch 28/50\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.0440 - accuracy: 0.9868 - val_loss: 0.5201 - val_accuracy: 0.8587\n",
      "Epoch 29/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0563 - accuracy: 0.9812 - val_loss: 0.5861 - val_accuracy: 0.8565\n",
      "Epoch 30/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0736 - accuracy: 0.9702 - val_loss: 0.6138 - val_accuracy: 0.8698\n",
      "Epoch 31/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0853 - accuracy: 0.9763 - val_loss: 0.6235 - val_accuracy: 0.8521\n",
      "Epoch 32/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1470 - accuracy: 0.9465 - val_loss: 0.5767 - val_accuracy: 0.8322\n",
      "Epoch 33/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1523 - accuracy: 0.9465 - val_loss: 0.5572 - val_accuracy: 0.8322\n",
      "Epoch 34/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0843 - accuracy: 0.9779 - val_loss: 0.4922 - val_accuracy: 0.8609\n",
      "Epoch 35/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0527 - accuracy: 0.9796 - val_loss: 0.4945 - val_accuracy: 0.8521\n",
      "Epoch 36/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0437 - accuracy: 0.9829 - val_loss: 0.5870 - val_accuracy: 0.8698\n",
      "Epoch 37/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0277 - accuracy: 0.9928 - val_loss: 0.6166 - val_accuracy: 0.8521\n",
      "Epoch 38/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0503 - accuracy: 0.9834 - val_loss: 0.5421 - val_accuracy: 0.8521\n",
      "Epoch 39/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.9829 - val_loss: 0.5921 - val_accuracy: 0.8477\n",
      "Epoch 40/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0715 - accuracy: 0.9752 - val_loss: 0.6258 - val_accuracy: 0.8146\n",
      "Epoch 41/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0547 - accuracy: 0.9840 - val_loss: 0.5149 - val_accuracy: 0.8675\n",
      "Epoch 42/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 0.9950 - val_loss: 0.5830 - val_accuracy: 0.8477\n",
      "Epoch 43/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0165 - accuracy: 0.9950 - val_loss: 0.6457 - val_accuracy: 0.8653\n",
      "Epoch 44/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 0.9950 - val_loss: 0.6718 - val_accuracy: 0.8587\n",
      "Epoch 45/50\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.0243 - accuracy: 0.9928 - val_loss: 0.6439 - val_accuracy: 0.8543\n",
      "Epoch 46/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0313 - accuracy: 0.9868 - val_loss: 0.7550 - val_accuracy: 0.8499\n",
      "Epoch 47/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0303 - accuracy: 0.9862 - val_loss: 0.8001 - val_accuracy: 0.8609\n",
      "Epoch 48/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0707 - accuracy: 0.9763 - val_loss: 0.8180 - val_accuracy: 0.8234\n",
      "Epoch 49/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1237 - accuracy: 0.9536 - val_loss: 0.7369 - val_accuracy: 0.8411\n",
      "Epoch 50/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.9757 - val_loss: 0.7831 - val_accuracy: 0.8477\n",
      "57/57 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2518 - accuracy: 0.9327 - val_loss: 0.1492 - val_accuracy: 0.9360\n",
      "Epoch 2/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1580 - accuracy: 0.9465 - val_loss: 0.0717 - val_accuracy: 0.9735\n",
      "Epoch 3/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1166 - accuracy: 0.9564 - val_loss: 0.0682 - val_accuracy: 0.9868\n",
      "Epoch 4/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0931 - accuracy: 0.9641 - val_loss: 0.0609 - val_accuracy: 0.9890\n",
      "Epoch 5/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0820 - accuracy: 0.9696 - val_loss: 0.0659 - val_accuracy: 0.9757\n",
      "Epoch 6/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0584 - accuracy: 0.9779 - val_loss: 0.0470 - val_accuracy: 0.9823\n",
      "Epoch 7/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9840 - val_loss: 0.0663 - val_accuracy: 0.9757\n",
      "Epoch 8/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0557 - accuracy: 0.9790 - val_loss: 0.0746 - val_accuracy: 0.9735\n",
      "Epoch 9/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0418 - accuracy: 0.9884 - val_loss: 0.0463 - val_accuracy: 0.9845\n",
      "Epoch 10/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 0.9845 - val_loss: 0.0922 - val_accuracy: 0.9581\n",
      "Epoch 11/50\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.0624 - accuracy: 0.9807 - val_loss: 0.1000 - val_accuracy: 0.9669\n",
      "Epoch 12/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.9763 - val_loss: 0.1058 - val_accuracy: 0.9669\n",
      "Epoch 13/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0550 - accuracy: 0.9779 - val_loss: 0.1043 - val_accuracy: 0.9558\n",
      "Epoch 14/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.9768 - val_loss: 0.1037 - val_accuracy: 0.9581\n",
      "Epoch 15/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0463 - accuracy: 0.9834 - val_loss: 0.1006 - val_accuracy: 0.9647\n",
      "Epoch 16/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0524 - accuracy: 0.9834 - val_loss: 0.2073 - val_accuracy: 0.9448\n",
      "Epoch 17/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0586 - accuracy: 0.9812 - val_loss: 0.1231 - val_accuracy: 0.9581\n",
      "Epoch 18/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0725 - accuracy: 0.9730 - val_loss: 0.1664 - val_accuracy: 0.9470\n",
      "Epoch 19/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1137 - accuracy: 0.9608 - val_loss: 0.2041 - val_accuracy: 0.9426\n",
      "Epoch 20/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0848 - accuracy: 0.9652 - val_loss: 0.1621 - val_accuracy: 0.9404\n",
      "Epoch 21/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0433 - accuracy: 0.9851 - val_loss: 0.1698 - val_accuracy: 0.9536\n",
      "Epoch 22/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0292 - accuracy: 0.9906 - val_loss: 0.1154 - val_accuracy: 0.9492\n",
      "Epoch 23/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0182 - accuracy: 0.9956 - val_loss: 0.1064 - val_accuracy: 0.9735\n",
      "Epoch 24/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 0.9989 - val_loss: 0.1058 - val_accuracy: 0.9581\n",
      "Epoch 25/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.9983 - val_loss: 0.1196 - val_accuracy: 0.9603\n",
      "Epoch 26/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.9956 - val_loss: 0.1435 - val_accuracy: 0.9558\n",
      "Epoch 27/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0161 - accuracy: 0.9950 - val_loss: 0.1427 - val_accuracy: 0.9581\n",
      "Epoch 28/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9939 - val_loss: 0.1705 - val_accuracy: 0.9492\n",
      "Epoch 29/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0421 - accuracy: 0.9829 - val_loss: 0.1910 - val_accuracy: 0.9492\n",
      "Epoch 30/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0332 - accuracy: 0.9890 - val_loss: 0.1948 - val_accuracy: 0.9426\n",
      "Epoch 31/50\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.0540 - accuracy: 0.9801 - val_loss: 0.3429 - val_accuracy: 0.8918\n",
      "Epoch 32/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0696 - accuracy: 0.9741 - val_loss: 0.1697 - val_accuracy: 0.9426\n",
      "Epoch 33/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1340 - accuracy: 0.9630 - val_loss: 0.4106 - val_accuracy: 0.9161\n",
      "Epoch 34/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1589 - accuracy: 0.9432 - val_loss: 0.2390 - val_accuracy: 0.8985\n",
      "Epoch 35/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0414 - accuracy: 0.9884 - val_loss: 0.2128 - val_accuracy: 0.9183\n",
      "Epoch 36/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 0.9967 - val_loss: 0.1949 - val_accuracy: 0.9338\n",
      "Epoch 37/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.9983 - val_loss: 0.1900 - val_accuracy: 0.9426\n",
      "Epoch 38/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.2055 - val_accuracy: 0.9404\n",
      "Epoch 39/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 0.9994 - val_loss: 0.2001 - val_accuracy: 0.9470\n",
      "Epoch 40/50\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2095 - val_accuracy: 0.9426\n",
      "Epoch 41/50\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2185 - val_accuracy: 0.9470\n",
      "Epoch 42/50\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2194 - val_accuracy: 0.9514\n",
      "Epoch 43/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2168 - val_accuracy: 0.9492\n",
      "Epoch 44/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2171 - val_accuracy: 0.9514\n",
      "Epoch 45/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2182 - val_accuracy: 0.9536\n",
      "Epoch 46/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2204 - val_accuracy: 0.9470\n",
      "Epoch 47/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2227 - val_accuracy: 0.9470\n",
      "Epoch 48/50\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2224 - val_accuracy: 0.9470\n",
      "Epoch 49/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 9.9509e-04 - accuracy: 1.0000 - val_loss: 0.2264 - val_accuracy: 0.9470\n",
      "Epoch 50/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 9.3982e-04 - accuracy: 1.0000 - val_loss: 0.2270 - val_accuracy: 0.9470\n",
      "57/57 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2408 - accuracy: 0.9338 - val_loss: 0.2576 - val_accuracy: 0.8962\n",
      "Epoch 2/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2101 - accuracy: 0.9216 - val_loss: 0.1287 - val_accuracy: 0.9514\n",
      "Epoch 3/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0784 - accuracy: 0.9741 - val_loss: 0.0681 - val_accuracy: 0.9735\n",
      "Epoch 4/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0312 - accuracy: 0.9901 - val_loss: 0.0764 - val_accuracy: 0.9647\n",
      "Epoch 5/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0346 - accuracy: 0.9895 - val_loss: 0.0668 - val_accuracy: 0.9779\n",
      "Epoch 6/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9851 - val_loss: 0.1100 - val_accuracy: 0.9558\n",
      "Epoch 7/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0789 - accuracy: 0.9669 - val_loss: 0.1996 - val_accuracy: 0.9316\n",
      "Epoch 8/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0801 - accuracy: 0.9702 - val_loss: 0.2042 - val_accuracy: 0.9294\n",
      "Epoch 9/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0811 - accuracy: 0.9713 - val_loss: 0.1595 - val_accuracy: 0.9382\n",
      "Epoch 10/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0623 - accuracy: 0.9752 - val_loss: 0.1280 - val_accuracy: 0.9492\n",
      "Epoch 11/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0435 - accuracy: 0.9851 - val_loss: 0.0861 - val_accuracy: 0.9603\n",
      "Epoch 12/50\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.0467 - accuracy: 0.9834 - val_loss: 0.1161 - val_accuracy: 0.9558\n",
      "Epoch 13/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0948 - accuracy: 0.9636 - val_loss: 0.1650 - val_accuracy: 0.9338\n",
      "Epoch 14/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0720 - accuracy: 0.9735 - val_loss: 0.1445 - val_accuracy: 0.9492\n",
      "Epoch 15/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0337 - accuracy: 0.9884 - val_loss: 0.1216 - val_accuracy: 0.9558\n",
      "Epoch 16/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0294 - accuracy: 0.9884 - val_loss: 0.1495 - val_accuracy: 0.9426\n",
      "Epoch 17/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 0.9945 - val_loss: 0.0934 - val_accuracy: 0.9647\n",
      "Epoch 18/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 0.9983 - val_loss: 0.0903 - val_accuracy: 0.9603\n",
      "Epoch 19/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.0827 - val_accuracy: 0.9603\n",
      "Epoch 20/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0755 - val_accuracy: 0.9713\n",
      "Epoch 21/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0920 - val_accuracy: 0.9581\n",
      "Epoch 22/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 0.9625\n",
      "Epoch 23/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0893 - val_accuracy: 0.9647\n",
      "Epoch 24/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.0891 - val_accuracy: 0.9669\n",
      "Epoch 25/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0190 - accuracy: 0.9945 - val_loss: 0.1431 - val_accuracy: 0.9448\n",
      "Epoch 26/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0657 - accuracy: 0.9763 - val_loss: 0.1759 - val_accuracy: 0.9426\n",
      "Epoch 27/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0539 - accuracy: 0.9834 - val_loss: 0.1683 - val_accuracy: 0.9448\n",
      "Epoch 28/50\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.0501 - accuracy: 0.9829 - val_loss: 0.2925 - val_accuracy: 0.9007\n",
      "Epoch 29/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1335 - accuracy: 0.9536 - val_loss: 0.2591 - val_accuracy: 0.9051\n",
      "Epoch 30/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.9845 - val_loss: 0.2311 - val_accuracy: 0.9183\n",
      "Epoch 31/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0215 - accuracy: 0.9950 - val_loss: 0.1959 - val_accuracy: 0.9227\n",
      "Epoch 32/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0177 - accuracy: 0.9956 - val_loss: 0.1890 - val_accuracy: 0.9360\n",
      "Epoch 33/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9972 - val_loss: 0.1671 - val_accuracy: 0.9360\n",
      "Epoch 34/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1594 - val_accuracy: 0.9382\n",
      "Epoch 35/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1584 - val_accuracy: 0.9426\n",
      "Epoch 36/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1622 - val_accuracy: 0.9426\n",
      "Epoch 37/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1682 - val_accuracy: 0.9404\n",
      "Epoch 38/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1612 - val_accuracy: 0.9448\n",
      "Epoch 39/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1644 - val_accuracy: 0.9448\n",
      "Epoch 40/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 9.9365e-04 - accuracy: 1.0000 - val_loss: 0.1651 - val_accuracy: 0.9448\n",
      "Epoch 41/50\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 8.8564e-04 - accuracy: 1.0000 - val_loss: 0.1741 - val_accuracy: 0.9426\n",
      "Epoch 42/50\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 8.0364e-04 - accuracy: 1.0000 - val_loss: 0.1743 - val_accuracy: 0.9426\n",
      "Epoch 43/50\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 7.2553e-04 - accuracy: 1.0000 - val_loss: 0.1745 - val_accuracy: 0.9426\n",
      "Epoch 44/50\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 6.6357e-04 - accuracy: 1.0000 - val_loss: 0.1759 - val_accuracy: 0.9382\n",
      "Epoch 45/50\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 6.1552e-04 - accuracy: 1.0000 - val_loss: 0.1749 - val_accuracy: 0.9426\n",
      "Epoch 46/50\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 5.6297e-04 - accuracy: 1.0000 - val_loss: 0.1819 - val_accuracy: 0.9360\n",
      "Epoch 47/50\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 5.3481e-04 - accuracy: 1.0000 - val_loss: 0.1782 - val_accuracy: 0.9426\n",
      "Epoch 48/50\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 5.0033e-04 - accuracy: 1.0000 - val_loss: 0.1790 - val_accuracy: 0.9426\n",
      "Epoch 49/50\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 4.5844e-04 - accuracy: 1.0000 - val_loss: 0.1832 - val_accuracy: 0.9404\n",
      "Epoch 50/50\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 4.3648e-04 - accuracy: 1.0000 - val_loss: 0.1853 - val_accuracy: 0.9404\n",
      "57/57 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision: 0.7194293213679083\n",
      "Average Recall: 0.6231975938934331\n",
      "Average F1-score: 0.6652196034272579\n",
      "Average AUC-ROC: 0.7727640132140574\n",
      "average val accuracy 0.8441501021385193\n",
      "average train accuracy 0.9773730635643005\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# Preprocess the data (e.g., handle missing values, normalize/scale features)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "df = pd.read_csv('train.csv')\n",
    "train_data1 = df.iloc[:, [7, 8, 21, 22, 24, 25, 27, 29]]\n",
    "train_labels = df.iloc[:, [0]]\n",
    "dftest = pd.read_csv('test.csv')\n",
    "val_data1 = dftest.iloc[:, [7, 8, 21, 22, 24, 25, 27, 29]]\n",
    "val_labels = dftest.iloc[:, [0]]\n",
    "\n",
    "# Create an instance of StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data\n",
    "scaler.fit(train_data1)\n",
    "\n",
    "# Scale the training data\n",
    "train_data = scaler.transform(train_data1)\n",
    "train_l = train_labels.to_numpy()\n",
    "# Scale the validation data\n",
    "val_data = scaler.transform(val_data1)\n",
    "val_l = val_labels.to_numpy()\n",
    "# Reshape the data for CNN input\n",
    "train_data = train_data.reshape(train_data.shape[0], train_data.shape[1], 1)\n",
    "val_data = val_data.reshape(val_data.shape[0], val_data.shape[1], 1)\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(train_data.shape[1], 1)))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 5\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "kf = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "train_scores = []\n",
    "val_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "auc_roc_scores = []\n",
    "\n",
    "for train_index, val_index in kf.split(train_data):\n",
    "    # Split the data into training and validation sets for the current fold\n",
    "    train_fold_data, val_fold_data = train_data[train_index], train_data[val_index]\n",
    "    train_fold_labels, val_fold_labels = train_l[train_index], train_l[val_index]\n",
    "\n",
    "    # Train the model on the current fold\n",
    "    history = model.fit(train_fold_data, train_fold_labels, epochs=50, batch_size=32, validation_data=(val_fold_data, val_fold_labels))\n",
    "\n",
    "    # Evaluate the model on the training and validation sets of the current fold\n",
    "    train_predictions = model.predict(train_fold_data)\n",
    "    val_predictions = model.predict(val_fold_data)\n",
    "\n",
    "    # Calculate accuracy scores for training and validation sets\n",
    "    train_acc = model.evaluate(train_fold_data, train_fold_labels, verbose=0)[1]\n",
    "    val_acc = model.evaluate(val_fold_data, val_fold_labels, verbose=0)[1]\n",
    "\n",
    "    train_scores.append(train_acc)\n",
    "    val_scores.append(val_acc)\n",
    "    val_predictions = model.predict(val_fold_data)\n",
    "    val_predictions = np.round(val_predictions) \n",
    "    precision = precision_score(val_fold_labels, val_predictions)\n",
    "    recall = recall_score(val_fold_labels, val_predictions)\n",
    "    f1 = f1_score(val_fold_labels, val_predictions)\n",
    "    auc_roc = roc_auc_score(val_fold_labels, val_predictions)\n",
    "\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    auc_roc_scores.append(auc_roc)\n",
    "\n",
    "# Calculate bias and variance\n",
    "bias = 1 - np.mean(train_scores)\n",
    "variance = np.var(val_scores, ddof=1)\n",
    "# Plot bias and variance\n",
    "plt.bar(['Bias', 'Variance'], [bias, variance])\n",
    "plt.xlabel('Error Type')\n",
    "plt.ylabel('Error Value')\n",
    "plt.title('Bias-Variance Tradeoff')\n",
    "plt.show()\n",
    "# Compute the average scores across all folds\n",
    "avg_precision = np.mean(precision_scores)\n",
    "avg_recall = np.mean(recall_scores)\n",
    "avg_f1 = np.mean(f1_scores)\n",
    "avg_auc_roc = np.mean(auc_roc_scores)\n",
    "avg_val_acc=np.mean(val_scores)\n",
    "avg_train_acc=np.mean(train_scores)\n",
    "print('Average Precision:', avg_precision)\n",
    "print('Average Recall:', avg_recall)\n",
    "print('Average F1-score:', avg_f1)\n",
    "print('Average AUC-ROC:', avg_auc_roc)\n",
    "print('average val accuracy',avg_val_acc)\n",
    "print('average train accuracy',avg_train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36d955c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  print confusion matrix of the test set\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Get the predictions on the test set\n",
    "test_predictions = model.predict(val_data)\n",
    "val_predictions = np.round(test_predictions)  # Convert probabilities to binary predictions\n",
    "#val_predictions = val_predictions.astype(int)\n",
    "# Get the confusion matrix\n",
    "cm = confusion_matrix(val_labels, val_predictions)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='g')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a643150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  print confusion matrix of the train set\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Get the predictions on the train set\n",
    "test_predictions = model.predict(train_data)\n",
    "val_predictions = np.round(test_predictions)  # Convert probabilities to binary predictions\n",
    "val_predictions = val_predictions.astype(int)\n",
    "# Get the confusion matrix\n",
    "cm = confusion_matrix(train_l, val_predictions)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='g')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702ad2ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
